{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/shashankprasanna/studiolab-sagemaker-examples/blob/main/studiolab-sagemaker-tf-deploy/tensorflow-serverless-inference.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model hosting with Amazon SageMaker from Amazon SageMaker Studio Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip -q install sagemaker tensorflow awscli boto3 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import sagemaker\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import shutil\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = {\n",
    "    \"Credentials\": {\n",
    "        \"AccessKeyId\": \"<AWS_ACCESS_KEY_ID>\",\n",
    "        \"SecretAccessKey\": \"<AWS_SECRET_ACCESS_KEY>\",\n",
    "        \"SessionToken\": \"<AWS_SESSION_TOKEN>\",\n",
    "    }\n",
    "}\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = credentials['Credentials']['AccessKeyId']\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = credentials['Credentials']['SecretAccessKey']\n",
    "os.environ[\"AWS_SESSION_TOKEN\"] = credentials['Credentials']['SessionToken']\n",
    "\n",
    "sagemaker_role='arn:aws:iam::<ACCOUNT_ID>:role/service-role/AmazonSageMaker-ExecutionRole-XXXXXXXXXXX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "region = sess.boto_region_name\n",
    "runtime = boto3.client(service_name='sagemaker-runtime')\n",
    "bucket = sess.default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download model and upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "def load_save_resnet50_model(model_path):\n",
    "    model = ResNet50(weights='imagenet')\n",
    "    shutil.rmtree(model_path, ignore_errors=True)\n",
    "    model.save(model_path, include_optimizer=False, save_format='tf')\n",
    "\n",
    "saved_model_dir = 'resnet50_saved_model' \n",
    "model_ver = '1'\n",
    "model_path = os.path.join(saved_model_dir, model_ver)\n",
    "\n",
    "load_save_resnet50_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('model.tar.gz', ignore_errors=True)\n",
    "!tar cvfz model.tar.gz code -C resnet50_saved_model ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'studiolab_deploy'\n",
    "s3_model_path = sess.upload_data(path='model.tar.gz', key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get model serving container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"tensorflow\",\n",
    "    region=region,\n",
    "    version=\"2.1\",\n",
    "    py_version=\"py3\",\n",
    "    image_scope='inference',\n",
    "    instance_type='ml.c5.large'\n",
    ")\n",
    "\n",
    "print('Container image with TensorFlow Serving:')\n",
    "image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "\n",
    "model = Model(image_uri=image_uri, \n",
    "              model_data=s3_model_path, \n",
    "              role=sagemaker_role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serverless.serverless_inference_config import ServerlessInferenceConfig\n",
    "\n",
    "serverless_config = ServerlessInferenceConfig(\n",
    "    memory_size_in_mb=6144,\n",
    "    max_concurrency=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = model.deploy(serverless_inference_config=serverless_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "file_name = 'kitten.jpg'\n",
    "!wget -q https://s3.amazonaws.com/model-server/inputs/kitten.jpg -O {file_name}\n",
    "with open(file_name, 'rb') as f:\n",
    "    image_data = f.read()\n",
    "\n",
    "Image(filename='kitten.jpg', width = 200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "response = runtime.invoke_endpoint(EndpointName=model.endpoint_name, \n",
    "                                   ContentType='application/x-image', \n",
    "                                   Body=image_data)\n",
    "probs = np.array(json.loads(response['Body'].read())['predictions'][0])\n",
    "keras.applications.resnet50.decode_predictions(np.expand_dims(probs, axis=0), top=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client = boto3.client(service_name='sagemaker')\n",
    "response = sm_client.delete_endpoint(EndpointName=model.endpoint_name)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client.list_endpoints()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "aws:Python",
   "language": "python",
   "name": "conda-env-aws-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
